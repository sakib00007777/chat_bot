{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkxKRQODfqVBRgEnbSyMz4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakib00007777/chat_bot/blob/main/rulebased_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Hcah2IiBgKND"
      },
      "outputs": [],
      "source": [
        "#libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import nltk\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input,Embedding ,LSTM ,Dense ,GlobalMaxPooling1D,Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile content.json\n",
        " {\n",
        "  \"intents\": [\n",
        "    {\n",
        "      \"tag\": \"greeting\",\n",
        "      \"input\": [\"hello\", \"is there anyone?\", \"hi\", \"whats up\", \"how are you?\"],\n",
        "      \"response\": [\n",
        "        \"Hi! Welcome to the world's first space tour agency! I am Astral! How can I help you?\",\n",
        "        \"Hey! Do you need any help?\",\n",
        "        \"Welcome! How may I help you?\",\n",
        "        \"Hey! How are you?\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"goodbye\",\n",
        "      \"input\": [\"thank you\", \"bye\", \"ok bye\", \"goodbye\", \"see you soon\", \"I will catch you later\"],\n",
        "      \"response\": [\n",
        "        \"Ok, bye!\",\n",
        "        \"Have a nice day!\",\n",
        "        \"Goodbye!\",\n",
        "        \"I will miss you!\",\n",
        "        \"Okay! Have a nice day!\",\n",
        "        \"Take care, dear!\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"where are you\",\n",
        "      \"input\": [\"where are you from?\", \"which country are you from?\", \"where do you live?\"],\n",
        "      \"response\": [\n",
        "        \"I live in a space station!\",\n",
        "        \"I am from space.\"\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88DuZb2yhknH",
        "outputId": "bc5da667-d54b-4c24-f19a-4698c120058d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting content.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the dataset\n",
        "\n",
        "with open('content.json') as content:\n",
        "    data1 = json.load(content)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fP8EwUJjIiPr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting all the data to lists\n",
        "tags=[]\n",
        "inputs=[]\n",
        "responses={}\n",
        "for intent in data1['intents']:\n",
        "   responses[intent['tag']]=intent['response']\n",
        "   for lines in intent['input']:\n",
        "    inputs.append(lines)\n",
        "    tags.append(intent['tag'])"
      ],
      "metadata": {
        "id": "slj6j03cKWM4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting into dataframe\n",
        "data = pd.DataFrame({\"inputs\":inputs,\n",
        "                     \"tags\":tags})"
      ],
      "metadata": {
        "id": "oEnNCGT7NXK5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing punctuation from the data\n",
        "import string\n",
        "data['inputs'] =data['inputs'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
        "data['inputs']=data['inputs'].apply(lambda wrd:''.join(wrd))\n"
      ],
      "metadata": {
        "id": "vYYBvGHKvMcN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize the data\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer=Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(data['inputs'])\n",
        "train=tokenizer.texts_to_sequences(data['inputs'])\n",
        "#apply padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train=pad_sequences(train)\n",
        "\n",
        "#encoding the outputs\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le= LabelEncoder()\n",
        "y_train=le.fit_transform(data['tags'])\n"
      ],
      "metadata": {
        "id": "taMGgkBCxSaN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define vocabulary\n",
        "vocabulary=len(tokenizer.word_index)\n",
        "print(\"number of unique words \", vocabulary)\n",
        "output_length=le.classes_.shape[0]\n",
        "print(\"output length \" ,output_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkULP_Uk0Bwp",
        "outputId": "27baf1dd-3b3b-4488-b410-15781d6b927f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unique words  26\n",
            "output length  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=x_train.shape[1]\n"
      ],
      "metadata": {
        "id": "mTEmZg8YF_la"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating model\n",
        "\n",
        "\n",
        "\n",
        "i=Input(shape=(input_shape,))\n",
        "x = Embedding (vocabulary+1,10)(i)\n",
        "x = LSTM(10, return_sequences=True)(x)\n",
        "x= Flatten()(x)\n",
        "x = Dense(output_length, activation=\"softmax\")(x)\n",
        "model = Model(i,x)\n"
      ],
      "metadata": {
        "id": "qj2Y3Nep10r-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qkWioYoc2x3c"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "train=model.fit(x_train,y_train,epochs=200)\n"
      ],
      "metadata": {
        "id": "cmdi2RNv34VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting model accuracy\n",
        "plt.plot(train.history['accuracy'],label='training set accuracy')\n",
        "plt.plot(train.history['loss'],label='training set loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "yjouqLY74JMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chatting\n",
        "import random\n",
        "while True:\n",
        "  texts_p=[]\n",
        "  prediction_input=input('You :')\n",
        "  #removing punctuation and converting into lower case\n",
        "  prediction_input=[letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
        "  prediction_input=''.join(prediction_input)\n",
        "  texts_p.append(prediction_input)\n",
        "  #tokenizing and padding\n",
        "  prediction_input=tokenizer.texts_to_sequences(texts_p)\n",
        "  prediction_input=np.array(prediction_input).reshape(-1)\n",
        "  prediction_input=pad_sequences([prediction_input],input_shape)\n",
        "\n",
        "  #getting output\n",
        "  output =model.predict(prediction_input)\n",
        "  output=output.argmax()\n",
        "  #finding the right tag and predicting\n",
        "  response_tag =le.inverse_transform([output])[0]\n",
        "  print(\"Astral :\" ,random.choice(responses[response_tag]))\n",
        "  if response_tag==\"goodbye\":\n",
        "    break\n"
      ],
      "metadata": {
        "id": "c5j4EJ6f4rik"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}